{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9367a6c3-5470-4f09-86a0-4cd499ecf1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from PIL.Image import fromarray, Image\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Dataset\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime as dt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "EPOCHS        = 3\n",
    "RANDOM_STATE  = 1337\n",
    "LEARNING_RATE = 1e-3 \n",
    "BATCH_SIZE    = 64\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de88216-3cb5-4849-9845-68cedcd4ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(device: str, epoch: int, optimizer, loss_fn, model, dataset: DataLoader):\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    it_eval = tqdm(enumerate(dataset), total=len(dataset))\n",
    "    running_loss = 0.\n",
    "    correct = 0\n",
    "    qt = 1\n",
    "    metrics = dict(tp=0, tn=0, fp=0, fn=0)\n",
    "    y_pred = list()\n",
    "    y_true = list()\n",
    "    with torch.no_grad():\n",
    "        for _, (x, y) in it_eval:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            output = model(x)\n",
    "            running_loss += loss_fn(output, y).item()\n",
    "            y_pred.extend(torch.argmax(output, 1).cpu().numpy())\n",
    "            y_true.extend(y.data.cpu().numpy())\n",
    "            correct += torch.sum(torch.argmax(output, 1).eq(y)).item()\n",
    "            qt += len(x)\n",
    "            desc = f\"[{now()}] Epoch {str(epoch).zfill(3)} Val. Acc: {correct/qt:.4f} Val. Loss: {running_loss / len(dataset):.8f}\"\n",
    "            it_eval.set_description(desc)\n",
    "\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics[\"tp\"] = tp\n",
    "    metrics[\"fp\"] = fp\n",
    "    metrics[\"tn\"] = tn\n",
    "    metrics[\"fn\"] = fn\n",
    "    return running_loss / len(dataset), correct/qt, metrics\n",
    "\n",
    "def train(device: str, epoch: int, optimizer, loss_fn, model, dataset: DataLoader):\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    qt = 1\n",
    "    correct = 0\n",
    "    it = tqdm(enumerate(dataset), total=len(dataset))\n",
    "\n",
    "    for _, (x, y) in it:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Make predictions for this batch\n",
    "        outputs = model(x)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        correct += torch.sum(torch.argmax(outputs, 1).eq(y)).item()\n",
    "        qt += len(x)\n",
    "    \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        desc = f\"[{now()}] Epoch {str(epoch).zfill(3)} Acc: {correct/qt:.4f} Loss: {running_loss / len(dataset):.8f}\"\n",
    "        it.set_description(desc)\n",
    "    return running_loss / len(dataset), correct/qt\n",
    "\n",
    "def now():\n",
    "    return dt.now().strftime(\"%d-%m-%Y %H-%M-%S\")\n",
    "\n",
    "class ToImage:\n",
    "        \n",
    "    def __call__(self, array: torch.Tensor, keep_normalization=True):\n",
    "        feat = array.shape[0]\n",
    "        n = int(np.ceil(feat ** 0.5))\n",
    "\n",
    "        array = array.cpu().numpy().copy()\n",
    "        \n",
    "        # Squared size with padding\n",
    "        array.resize((n, n))\n",
    "        if not keep_normalization:\n",
    "            return (array * 255).astype(np.uint8)\n",
    "\n",
    "        return torch.Tensor(array.astype(np.float32)).unsqueeze(0)\n",
    "\n",
    "class Resize:\n",
    "    def __init__(self, shape):\n",
    "        self._shape = shape\n",
    "\n",
    "    def __call__(self, X, rgb=True):\n",
    "        device = 'cpu'\n",
    "        \n",
    "        if isinstance(X, Image):\n",
    "            X = np.array(X)\n",
    "        \n",
    "        if isinstance(X, torch.Tensor):\n",
    "            device = X.device.type\n",
    "            X = X.squeeze(0).cpu().numpy()\n",
    "\n",
    "        ret = cv2.resize(X, dsize=self._shape, interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        if rgb:\n",
    "            ret = cv2.cvtColor(ret, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        ret = torch.Tensor(ret)\n",
    "        if rgb:\n",
    "            ret = ret.view(3, *self._shape)\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            # ret = ret.to('cuda')\n",
    "            ...\n",
    "            \n",
    "        return ret\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, subset: Tuple[torch.Tensor, torch.Tensor], transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[0][index, :], self.subset[1][index]\n",
    "    \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.subset[0].size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ef260b-f8e8-46a2-9558-2ab52b021ef3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd1948d-18cc-4c3a-9a63-234bf6684f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('/data/img_nids/mlp/NIGEL_2014_01.csv', skiprows=1, delimiter=\",\", dtype=np.float32)\n",
    "X, y = data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4059e3cc-2cd6-4b6d-a152-1374e72f193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cdbce56-0db6-4c05-9f7d-5be2e247ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(max_iter=EPOCHS, random_state=RANDOM_STATE, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54cc5f49-451e-433e-a4dd-00ad6267e007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259946, 2049)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb55b404-aa1d-4256-a4b5-9f27d93a908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.array(list(map(lambda x: ToImage().fit_transform(x, None), data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a7520d0-0370-420c-83d6-59884652a54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550045736,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5648e29-3953-4b03-8985-542543f1721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71710 67982 4525 797 01\n",
      "37297 27419 10381 503 02\n",
      "42576 31895 11578 897 03\n",
      "27906 27174 1133 401 04\n",
      "66319 45444 21753 878 05\n",
      "36818 36111 1339 632 06\n",
      "115744 76676 39397 329 07\n",
      "53498 51938 2114 554 08\n",
      "50008 193 49862 47 09\n",
      "82763 57635 25643 515 10\n",
      "60378 325273 8795 273690 11\n",
      "128635 87549 42424 1338 12\n"
     ]
    }
   ],
   "source": [
    "w = []\n",
    "for month in [str(i).zfill(2) for i in range(1, 13)]:\n",
    "    path = f'/data/img_nids/mlp/NIGEL_2014_{month}.csv'\n",
    "\n",
    "    data = np.loadtxt(path,skiprows=1, delimiter=\",\", dtype=np.float32)\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    if month == '01':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data[:, :-1], data[:, -1], test_size=.3, random_state=RANDOM_STATE)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        print(classifier.score(X_test, y_test), month)\n",
    "    else:\n",
    "        y_pred = classifier.predict(data[:, :-1])\n",
    "        tn, fp, fn, tp = confusion_matrix(data[:, -1], y_pred).ravel()\n",
    "        print(tp, tn, fp, fn, month)\n",
    "        w.append(dict(fp=fp, fn=fn, tp=tp, tn=tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16d4a747-331d-417a-88ec-33854bb202f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = []\n",
    "fnr = []\n",
    "\n",
    "for row in w:\n",
    "    fpr.append(row['fp'] / (row['fp'] + row['tn']))\n",
    "    fnr.append(row['fn'] / (row['fn'] + row['tp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2c1f8fa-ce74-4de2-8c14-6c737eb91807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06240776752589405,\n",
       " 0.2746296296296296,\n",
       " 0.2663262254732823,\n",
       " 0.040025435404670226,\n",
       " 0.3237198089200411,\n",
       " 0.0357543391188251,\n",
       " 0.3394157125257381,\n",
       " 0.03911048619847554,\n",
       " 0.996144241334532,\n",
       " 0.3079204591848988,\n",
       " 0.026326975346336674,\n",
       " 0.32640625360651826]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8f61e56-16c0-43eb-b280-7f71201af77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010992042147654708,\n",
       " 0.013306878306878307,\n",
       " 0.020633496653095024,\n",
       " 0.014166107323276928,\n",
       " 0.013066059496703721,\n",
       " 0.016875834445927905,\n",
       " 0.0028344231647325392,\n",
       " 0.010249389476800118,\n",
       " 0.0009389671361502347,\n",
       " 0.006184106246547708,\n",
       " 0.819264341391573,\n",
       " 0.010294445769505974]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9e070b2-7f5e-4808-ad96-0b53a9edb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.csv', 'w') as fp:\n",
    "    fp.write(\"fpr,fnr\\n\")\n",
    "    for _fp, _fn in zip(fpr, fnr):\n",
    "        fp.write(f\"{_fp},{_fn}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b226c-487a-44d2-9456-552bd6047b64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68391b1-cebd-4906-8de1-f48178d48778",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self._out_features = out_features\n",
    "        self._in_features  = in_features\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, in_features, kernel_size=4)\n",
    "        self.conv2 = nn.Conv2d(in_features, 32, kernel_size=4)\n",
    "\n",
    "        # out_channels (conv2) * saída da último max pooling ** 2\n",
    "        self.fc1 = nn.Linear(32 * 35 * 35, 512) \n",
    "        self.fc2 = nn.Linear(512, out_features)\n",
    "        self.dropout = nn.Dropout(p=0.4) \n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2) # Max pooling over a (2, 2) window\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 3) # If the size is a square, you can specify with a single number\n",
    "\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.dropout(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee3b93c0-2527-459b-b8a4-94ef2e67e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('/data/img_nids/mlp/NIGEL_2014_01.csv', skiprows=1, delimiter=',', dtype=np.float32)\n",
    "X, y = data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "040afbd1-92c0-48cc-a075-68bd3c8a5e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145014,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8156e99-b1e5-437e-ad21-72a9860a589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = SimpleNN(224, 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26f6704-cb13-4beb-89d2-cc4905bbbc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=RANDOM_STATE)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=.3, random_state=RANDOM_STATE)\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_test  = torch.Tensor(X_test)\n",
    "y_test  = torch.LongTensor(y_test)\n",
    "X_val   = torch.Tensor(X_val)\n",
    "y_val   = torch.LongTensor(y_val)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToImage(),\n",
    "    Resize((224, 224)),\n",
    "])\n",
    "\n",
    "data_train = DataLoader(CustomDataset(subset=(X_train, y_train), transform=transform), shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "data_test  = DataLoader(CustomDataset(subset=(X_test, y_test), transform=transform), shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "data_val   = DataLoader(CustomDataset(subset=(X_val, y_val), transform=transform), shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "\n",
    "loss_fn   = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f8a2260-164a-41ab-91ba-85a4713683bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1609e-02,  2.1609e-02,  5.4941e-02,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 4.0421e-04,  4.0421e-04,  4.0421e-04,  ...,  5.6651e-02,\n",
       "          2.4317e-02,  2.4317e-02],\n",
       "        [ 2.4317e-02, -4.0131e-04, -4.0131e-04,  ...,  6.8874e-06,\n",
       "          6.8874e-06, -4.1733e-04],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.5416e-12,\n",
       "          5.5416e-12,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.3460e-04,\n",
       "          4.4298e-05,  4.4298e-05]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(X_train[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f656cee-05d9-4ea7-aa70-169f3a55c399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 12-28-25] Epoch 001 Acc: 0.9433 Loss: 0.36980523: 100%|██████████| 1587/1587 [05:24<00:00,  4.89it/s]\n",
      "[02-11-2023 12-28-36] Epoch 001 Val. Acc: 0.9453 Val. Loss: 0.36782611: 100%|██████████| 204/204 [00:10<00:00, 18.81it/s]\n",
      "[02-11-2023 12-34-04] Epoch 002 Acc: 0.9415 Loss: 0.37161473: 100%|██████████| 1587/1587 [05:28<00:00,  4.84it/s]\n",
      "[02-11-2023 12-34-15] Epoch 002 Val. Acc: 0.9446 Val. Loss: 0.36858508: 100%|██████████| 204/204 [00:10<00:00, 18.82it/s]\n",
      "[02-11-2023 12-39-46] Epoch 003 Acc: 0.9465 Loss: 0.36673708: 100%|██████████| 1587/1587 [05:30<00:00,  4.81it/s]\n",
      "[02-11-2023 12-39-57] Epoch 003 Val. Acc: 0.9450 Val. Loss: 0.36822003: 100%|██████████| 204/204 [00:10<00:00, 18.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = train(device, epoch, optimizer, loss_fn, model, data_train)\n",
    "    val_loss, val_acc, _ = validate(device, epoch, optimizer, loss_fn, model, data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e1b4c87-2c44-40ef-84a6-5f03f4be0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.loadtxt(f'/data/img_nids/mlp/NIGEL_2014_02.csv', skiprows=1, delimiter=',', dtype=np.float32)\n",
    "        \n",
    "X_test2, y_test2 = data2[:, :-1], data2[:, -1]\n",
    "X_test2  = torch.Tensor(X_test2)\n",
    "y_test2  = torch.LongTensor(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0ff24a0-3879-4152-99be-d4653558105a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0562, 0.0000, 0.0000,  ..., 0.0107, 0.0673, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0788, 0.0000],\n",
       "        [0.1454, 0.1223, 0.0000,  ..., 0.0439, 0.2630, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0882, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0882, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0882, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc253bb6-23c1-4411-87df-bc92fa419827",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.loadtxt(f'/data/img_nids/mlp/NIGEL_2014_01.csv', skiprows=1, delimiter=',', dtype=np.float32)\n",
    "        \n",
    "X_test1, y_test1 = data1[:, :-1], data1[:, -1]\n",
    "X_test1  = torch.Tensor(X_test1)\n",
    "y_test1  = torch.LongTensor(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d8db1c8-d06d-47b2-9555-297dd285353b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0353, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.2826, 0.0000, 0.0000,  ..., 0.0000, 0.0268, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1898, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1898, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1898, 0.0000]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12cc8920-dadd-40f6-bed4-818c394e4a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 12-54-21] Epoch 003 Val. Acc: 0.9477 Val. Loss: 0.36559208: 100%|██████████| 2266/2266 [01:58<00:00, 19.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 70468, 'tn': 66957, 'fp': 5550, 'fn': 2039} 01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 12-55-35] Epoch 003 Val. Acc: 0.9485 Val. Loss: 0.36476093: 100%|██████████| 1182/1182 [01:02<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 36498, 'tn': 35206, 'fp': 2594, 'fn': 1302} 02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 12-57-00] Epoch 003 Val. Acc: 0.9394 Val. Loss: 0.37384153: 100%|██████████| 1359/1359 [01:11<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 40728, 'tn': 40949, 'fp': 2524, 'fn': 2745} 03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 12-57-56] Epoch 003 Val. Acc: 0.9594 Val. Loss: 0.35378276: 100%|██████████| 885/885 [00:46<00:00, 18.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 26912, 'tn': 27407, 'fp': 900, 'fn': 1395} 04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-00-08] Epoch 003 Val. Acc: 0.9705 Val. Loss: 0.34278195: 100%|██████████| 2100/2100 [01:50<00:00, 18.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 65142, 'tn': 65284, 'fp': 1913, 'fn': 2055} 05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-01-23] Epoch 003 Val. Acc: 0.9540 Val. Loss: 0.35921598: 100%|██████████| 1171/1171 [01:02<00:00, 18.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 35224, 'tn': 36231, 'fp': 1219, 'fn': 2226} 06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-05-12] Epoch 003 Val. Acc: 0.9597 Val. Loss: 0.35354299: 100%|██████████| 3628/3628 [03:11<00:00, 18.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 112651, 'tn': 110144, 'fp': 5929, 'fn': 3422} 07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-06-59] Epoch 003 Val. Acc: 0.9616 Val. Loss: 0.35163130: 100%|██████████| 1690/1690 [01:30<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 51599, 'tn': 52355, 'fp': 1697, 'fn': 2453} 08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-08-41] Epoch 003 Val. Acc: 0.9505 Val. Loss: 0.36274437: 100%|██████████| 1565/1565 [01:23<00:00, 18.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 46620, 'tn': 48532, 'fp': 1523, 'fn': 3435} 09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-11-26] Epoch 003 Val. Acc: 0.9533 Val. Loss: 0.35995749: 100%|██████████| 2603/2603 [02:19<00:00, 18.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 79449, 'tn': 79327, 'fp': 3951, 'fn': 3829} 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-22-21] Epoch 003 Val. Acc: 0.9695 Val. Loss: 0.34372303: 100%|██████████| 10440/10440 [09:16<00:00, 18.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 331440, 'tn': 316342, 'fp': 17726, 'fn': 2628} 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-26-38] Epoch 003 Val. Acc: 0.9462 Val. Loss: 0.36702626: 100%|██████████| 4062/4062 [03:37<00:00, 18.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 126761, 'tn': 119207, 'fp': 10766, 'fn': 3212} 12\n"
     ]
    }
   ],
   "source": [
    "all_metrics = dict()\n",
    "for month in [str(i).zfill(2) for i in range(1, 13)]:\n",
    "    #if month != '01':\n",
    "    data = np.loadtxt(f'/data/img_nids/mlp/NIGEL_2014_{month}.csv', skiprows=1, delimiter=',', dtype=np.float32)\n",
    "        \n",
    "    X_test, y_test = data[:, :-1], data[:, -1]\n",
    "    X_test  = torch.Tensor(X_test)\n",
    "    y_test  = torch.LongTensor(y_test)\n",
    "\n",
    "    #cd = CustomDataset(subset=(X_test, y_test), transform=transform)\n",
    "    #data_test  = DataLoader(cd, shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "    data_test = DataLoader(CustomDataset(subset=(X_test, y_test), transform=transform), shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "\n",
    "    _, _, metrics = validate(device, epoch, optimizer, loss_fn, model, data_test)\n",
    "    all_metrics[month] = metrics\n",
    "    print(all_metrics[month], month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db143a7-13c9-47b5-b4bc-360104fd17b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01': {'tp': 70468, 'tn': 66957, 'fp': 5550, 'fn': 2039},\n",
       " '02': {'tp': 36498, 'tn': 35206, 'fp': 2594, 'fn': 1302},\n",
       " '03': {'tp': 40728, 'tn': 40949, 'fp': 2524, 'fn': 2745},\n",
       " '04': {'tp': 26912, 'tn': 27407, 'fp': 900, 'fn': 1395},\n",
       " '05': {'tp': 65142, 'tn': 65284, 'fp': 1913, 'fn': 2055},\n",
       " '06': {'tp': 35224, 'tn': 36231, 'fp': 1219, 'fn': 2226},\n",
       " '07': {'tp': 112651, 'tn': 110144, 'fp': 5929, 'fn': 3422},\n",
       " '08': {'tp': 51599, 'tn': 52355, 'fp': 1697, 'fn': 2453},\n",
       " '09': {'tp': 46620, 'tn': 48532, 'fp': 1523, 'fn': 3435},\n",
       " '10': {'tp': 79449, 'tn': 79327, 'fp': 3951, 'fn': 3829},\n",
       " '11': {'tp': 331440, 'tn': 316342, 'fp': 17726, 'fn': 2628},\n",
       " '12': {'tp': 126761, 'tn': 119207, 'fp': 10766, 'fn': 3212}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff6ef3a4-38f3-4db0-bd50-747e423e4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = []\n",
    "fnr = []\n",
    "\n",
    "for row in all_metrics.values():\n",
    "    fpr.append(row['fp'] / (row['fp'] + row['tn']))\n",
    "    fnr.append(row['fn'] / (row['fn'] + row['tp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01c721e2-30c6-4a4b-b911-a51eefc4e928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.07654433365054408,\n",
       "  0.06862433862433863,\n",
       "  0.058059025142042184,\n",
       "  0.03179425583777864,\n",
       "  0.02846853282140572,\n",
       "  0.032550066755674234,\n",
       "  0.05107992384103108,\n",
       "  0.03139569303633538,\n",
       "  0.030426530816102287,\n",
       "  0.04744350248565047,\n",
       "  0.05306105343822216,\n",
       "  0.08283258830680218],\n",
       " [0.028121422759181874,\n",
       "  0.034444444444444444,\n",
       "  0.0631426402594714,\n",
       "  0.04928109654855689,\n",
       "  0.030581722398321354,\n",
       "  0.059439252336448596,\n",
       "  0.02948144702040957,\n",
       "  0.04538222452453193,\n",
       "  0.06862451303566078,\n",
       "  0.04597852974374985,\n",
       "  0.0078666618772226,\n",
       "  0.0247128249713402])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02330ee3-0540-43e4-921b-127a1afbf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_cnn.csv', 'w') as fp:\n",
    "    fp.write(\"fpr,fnr\\n\")\n",
    "    for _fp, _fn in zip(fpr, fnr):\n",
    "        fp.write(f\"{_fp},{_fn}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ca7d7-183f-472f-80ee-779b6d3c401a",
   "metadata": {},
   "source": [
    "# MLP (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9bb0f72-ce28-4150-a177-7f9159ecee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_feat * in_feat * 3, 200)\n",
    "        self.fc2 = nn.Linear(200, out_feat)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd36f19-0914-4240-9daa-56244391b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('/data/img_nids/mlp/NIGEL_2014_01.csv', skiprows=1, delimiter=',', dtype=np.float32)\n",
    "X, y = data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6502ce5-d0be-47ce-83cb-19df715a7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "s = SimpleMLP(224, 2)\n",
    "s = s.to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=RANDOM_STATE)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=.3, random_state=RANDOM_STATE)\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_test  = torch.Tensor(X_test)\n",
    "y_test  = torch.LongTensor(y_test)\n",
    "X_val   = torch.Tensor(X_val)\n",
    "y_val   = torch.LongTensor(y_val)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToImage(),\n",
    "    Resize((224, 224)),\n",
    "])\n",
    "\n",
    "BATCH_SIZE=1024\n",
    "\n",
    "data_train = DataLoader(CustomDataset(subset=(X_train, y_train), transform=transform), shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "data_test  = DataLoader(CustomDataset(subset=(X_test, y_test), transform=transform), shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "data_val   = DataLoader(CustomDataset(subset=(X_val, y_val), transform=transform), shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "\n",
    "loss_fn   = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(s.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22d7805d-3ba5-4f47-b5be-1bdcbd8e7c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-38-15] Epoch 001 Acc: 0.9414 Loss: 0.37104732: 100%|██████████| 100/100 [00:28<00:00,  3.50it/s]\n",
      "[02-11-2023 13-38-19] Epoch 001 Val. Acc: 0.9444 Val. Loss: 0.36888554: 100%|██████████| 13/13 [00:04<00:00,  3.14it/s]\n",
      "[02-11-2023 13-38-47] Epoch 002 Acc: 0.9500 Loss: 0.36354794: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n",
      "[02-11-2023 13-38-52] Epoch 002 Val. Acc: 0.9530 Val. Loss: 0.36057164: 100%|██████████| 13/13 [00:04<00:00,  3.15it/s]\n",
      "[02-11-2023 13-39-20] Epoch 003 Acc: 0.9549 Loss: 0.35816712: 100%|██████████| 100/100 [00:27<00:00,  3.63it/s]\n",
      "[02-11-2023 13-39-24] Epoch 003 Val. Acc: 0.9530 Val. Loss: 0.35993358: 100%|██████████| 13/13 [00:04<00:00,  3.23it/s]\n",
      "[02-11-2023 13-39-52] Epoch 004 Acc: 0.9549 Loss: 0.35851328: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "[02-11-2023 13-39-56] Epoch 004 Val. Acc: 0.9531 Val. Loss: 0.36020758: 100%|██████████| 13/13 [00:04<00:00,  3.13it/s]\n",
      "[02-11-2023 13-40-24] Epoch 005 Acc: 0.9549 Loss: 0.35836409: 100%|██████████| 100/100 [00:27<00:00,  3.63it/s]\n",
      "[02-11-2023 13-40-29] Epoch 005 Val. Acc: 0.9528 Val. Loss: 0.36024371: 100%|██████████| 13/13 [00:04<00:00,  3.15it/s]\n",
      "[02-11-2023 13-40-57] Epoch 006 Acc: 0.9549 Loss: 0.35826639: 100%|██████████| 100/100 [00:28<00:00,  3.57it/s]\n",
      "[02-11-2023 13-41-01] Epoch 006 Val. Acc: 0.9530 Val. Loss: 0.36027099: 100%|██████████| 13/13 [00:04<00:00,  3.21it/s]\n",
      "[02-11-2023 13-41-30] Epoch 007 Acc: 0.9549 Loss: 0.35810227: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n",
      "[02-11-2023 13-41-34] Epoch 007 Val. Acc: 0.9530 Val. Loss: 0.36005533: 100%|██████████| 13/13 [00:04<00:00,  3.17it/s]\n",
      "[02-11-2023 13-42-02] Epoch 008 Acc: 0.9548 Loss: 0.35820690: 100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n",
      "[02-11-2023 13-42-06] Epoch 008 Val. Acc: 0.9533 Val. Loss: 0.35965339: 100%|██████████| 13/13 [00:04<00:00,  3.22it/s]\n",
      "[02-11-2023 13-42-34] Epoch 009 Acc: 0.9548 Loss: 0.35834776: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n",
      "[02-11-2023 13-42-39] Epoch 009 Val. Acc: 0.9534 Val. Loss: 0.35982465: 100%|██████████| 13/13 [00:04<00:00,  3.12it/s]\n",
      "[02-11-2023 13-43-07] Epoch 010 Acc: 0.9547 Loss: 0.35850280: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n",
      "[02-11-2023 13-43-11] Epoch 010 Val. Acc: 0.9527 Val. Loss: 0.36030804: 100%|██████████| 13/13 [00:04<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10 + 1):\n",
    "    train_loss, train_acc = train(device, epoch, optimizer, loss_fn, s, data_train)\n",
    "    val_loss, val_acc, _ = validate(device, epoch, optimizer, loss_fn, s, data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a398d644-5e18-44c7-baef-70516f91ca3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-48-46] Epoch 010 Val. Acc: 0.9549 Val. Loss: 0.35838755: 100%|██████████| 142/142 [00:38<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-49-19] Epoch 010 Val. Acc: 0.9560 Val. Loss: 0.35720385: 100%|██████████| 74/74 [00:20<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}, '02': {'tp': 37319, 'tn': 34955, 'fp': 2845, 'fn': 481}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-49-56] Epoch 010 Val. Acc: 0.9552 Val. Loss: 0.35801235: 100%|██████████| 85/85 [00:23<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}, '02': {'tp': 37319, 'tn': 34955, 'fp': 2845, 'fn': 481}, '03': {'tp': 42352, 'tn': 40698, 'fp': 2775, 'fn': 1121}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-50-24] Epoch 010 Val. Acc: 0.9680 Val. Loss: 0.34517964: 100%|██████████| 56/56 [00:15<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}, '02': {'tp': 37319, 'tn': 34955, 'fp': 2845, 'fn': 481}, '03': {'tp': 42352, 'tn': 40698, 'fp': 2775, 'fn': 1121}, '04': {'tp': 27515, 'tn': 27286, 'fp': 1021, 'fn': 792}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-51-22] Epoch 010 Val. Acc: 0.9777 Val. Loss: 0.33555658: 100%|██████████| 132/132 [00:35<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}, '02': {'tp': 37319, 'tn': 34955, 'fp': 2845, 'fn': 481}, '03': {'tp': 42352, 'tn': 40698, 'fp': 2775, 'fn': 1121}, '04': {'tp': 27515, 'tn': 27286, 'fp': 1021, 'fn': 792}, '05': {'tp': 66337, 'tn': 65059, 'fp': 2138, 'fn': 860}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-51-54] Epoch 010 Val. Acc: 0.9687 Val. Loss: 0.34464903: 100%|██████████| 74/74 [00:20<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}, '02': {'tp': 37319, 'tn': 34955, 'fp': 2845, 'fn': 481}, '03': {'tp': 42352, 'tn': 40698, 'fp': 2775, 'fn': 1121}, '04': {'tp': 27515, 'tn': 27286, 'fp': 1021, 'fn': 792}, '05': {'tp': 66337, 'tn': 65059, 'fp': 2138, 'fn': 860}, '06': {'tp': 36471, 'tn': 36087, 'fp': 1363, 'fn': 979}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-53-33] Epoch 010 Val. Acc: 0.9672 Val. Loss: 0.34599504: 100%|██████████| 227/227 [01:01<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}, '02': {'tp': 37319, 'tn': 34955, 'fp': 2845, 'fn': 481}, '03': {'tp': 42352, 'tn': 40698, 'fp': 2775, 'fn': 1121}, '04': {'tp': 27515, 'tn': 27286, 'fp': 1021, 'fn': 792}, '05': {'tp': 66337, 'tn': 65059, 'fp': 2138, 'fn': 860}, '06': {'tp': 36471, 'tn': 36087, 'fp': 1363, 'fn': 979}, '07': {'tp': 114963, 'tn': 109578, 'fp': 6495, 'fn': 1110}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-54-19] Epoch 010 Val. Acc: 0.9732 Val. Loss: 0.34005924: 100%|██████████| 106/106 [00:28<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}, '02': {'tp': 37319, 'tn': 34955, 'fp': 2845, 'fn': 481}, '03': {'tp': 42352, 'tn': 40698, 'fp': 2775, 'fn': 1121}, '04': {'tp': 27515, 'tn': 27286, 'fp': 1021, 'fn': 792}, '05': {'tp': 66337, 'tn': 65059, 'fp': 2138, 'fn': 860}, '06': {'tp': 36471, 'tn': 36087, 'fp': 1363, 'fn': 979}, '07': {'tp': 114963, 'tn': 109578, 'fp': 6495, 'fn': 1110}, '08': {'tp': 53053, 'tn': 52151, 'fp': 1901, 'fn': 999}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-55-02] Epoch 010 Val. Acc: 0.9670 Val. Loss: 0.34625103: 100%|██████████| 98/98 [00:26<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}, '02': {'tp': 37319, 'tn': 34955, 'fp': 2845, 'fn': 481}, '03': {'tp': 42352, 'tn': 40698, 'fp': 2775, 'fn': 1121}, '04': {'tp': 27515, 'tn': 27286, 'fp': 1021, 'fn': 792}, '05': {'tp': 66337, 'tn': 65059, 'fp': 2138, 'fn': 860}, '06': {'tp': 36471, 'tn': 36087, 'fp': 1363, 'fn': 979}, '07': {'tp': 114963, 'tn': 109578, 'fp': 6495, 'fn': 1110}, '08': {'tp': 53053, 'tn': 52151, 'fp': 1901, 'fn': 999}, '09': {'tp': 48458, 'tn': 48347, 'fp': 1708, 'fn': 1597}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-56-13] Epoch 010 Val. Acc: 0.9686 Val. Loss: 0.34460838: 100%|██████████| 163/163 [00:44<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}, '02': {'tp': 37319, 'tn': 34955, 'fp': 2845, 'fn': 481}, '03': {'tp': 42352, 'tn': 40698, 'fp': 2775, 'fn': 1121}, '04': {'tp': 27515, 'tn': 27286, 'fp': 1021, 'fn': 792}, '05': {'tp': 66337, 'tn': 65059, 'fp': 2138, 'fn': 860}, '06': {'tp': 36471, 'tn': 36087, 'fp': 1363, 'fn': 979}, '07': {'tp': 114963, 'tn': 109578, 'fp': 6495, 'fn': 1110}, '08': {'tp': 53053, 'tn': 52151, 'fp': 1901, 'fn': 999}, '09': {'tp': 48458, 'tn': 48347, 'fp': 1708, 'fn': 1597}, '10': {'tp': 82357, 'tn': 78976, 'fp': 4302, 'fn': 921}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 13-59-15] Epoch 010 Val. Acc: 0.9703 Val. Loss: 0.15543642:  45%|████▌     | 296/653 [01:21<01:32,  3.85it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda3c099e10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "[02-11-2023 13-59-16] Epoch 010 Val. Acc: 0.9704 Val. Loss: 0.15646766:  46%|████▌     | 298/653 [01:22<01:31,  3.90it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda3c099e10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda3c099e10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "[02-11-2023 13-59-17] Epoch 010 Val. Acc: 0.9704 Val. Loss: 0.15752731:  46%|████▌     | 300/653 [01:22<01:32,  3.80it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda3c099e10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda3c099e10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "[02-11-2023 13-59-17] Epoch 010 Val. Acc: 0.9704 Val. Loss: 0.15858247:  46%|████▌     | 302/653 [01:23<01:39,  3.53it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda3c099e10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda3c099e10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "[02-11-2023 13-59-18] Epoch 010 Val. Acc: 0.9703 Val. Loss: 0.15911610:  46%|████▋     | 303/653 [01:24<01:48,  3.22it/s]: can only test a child process\n",
      "[02-11-2023 13-59-18] Epoch 010 Val. Acc: 0.9703 Val. Loss: 0.15963780:  47%|████▋     | 304/653 [01:24<01:35,  3.64it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda3c099e10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/pedro/Projects/sac_2023/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "[02-11-2023 14-00-52] Epoch 010 Val. Acc: 0.9700 Val. Loss: 0.34320422: 100%|██████████| 653/653 [02:58<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}, '02': {'tp': 37319, 'tn': 34955, 'fp': 2845, 'fn': 481}, '03': {'tp': 42352, 'tn': 40698, 'fp': 2775, 'fn': 1121}, '04': {'tp': 27515, 'tn': 27286, 'fp': 1021, 'fn': 792}, '05': {'tp': 66337, 'tn': 65059, 'fp': 2138, 'fn': 860}, '06': {'tp': 36471, 'tn': 36087, 'fp': 1363, 'fn': 979}, '07': {'tp': 114963, 'tn': 109578, 'fp': 6495, 'fn': 1110}, '08': {'tp': 53053, 'tn': 52151, 'fp': 1901, 'fn': 999}, '09': {'tp': 48458, 'tn': 48347, 'fp': 1708, 'fn': 1597}, '10': {'tp': 82357, 'tn': 78976, 'fp': 4302, 'fn': 921}, '11': {'tp': 333415, 'tn': 314704, 'fp': 19364, 'fn': 653}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02-11-2023 14-02-40] Epoch 010 Val. Acc: 0.9517 Val. Loss: 0.36155899: 100%|██████████| 254/254 [01:08<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'tp': 71998, 'tn': 66470, 'fp': 6037, 'fn': 509}, '02': {'tp': 37319, 'tn': 34955, 'fp': 2845, 'fn': 481}, '03': {'tp': 42352, 'tn': 40698, 'fp': 2775, 'fn': 1121}, '04': {'tp': 27515, 'tn': 27286, 'fp': 1021, 'fn': 792}, '05': {'tp': 66337, 'tn': 65059, 'fp': 2138, 'fn': 860}, '06': {'tp': 36471, 'tn': 36087, 'fp': 1363, 'fn': 979}, '07': {'tp': 114963, 'tn': 109578, 'fp': 6495, 'fn': 1110}, '08': {'tp': 53053, 'tn': 52151, 'fp': 1901, 'fn': 999}, '09': {'tp': 48458, 'tn': 48347, 'fp': 1708, 'fn': 1597}, '10': {'tp': 82357, 'tn': 78976, 'fp': 4302, 'fn': 921}, '11': {'tp': 333415, 'tn': 314704, 'fp': 19364, 'fn': 653}, '12': {'tp': 128969, 'tn': 118416, 'fp': 11557, 'fn': 1004}}\n"
     ]
    }
   ],
   "source": [
    "all_metrics = dict()\n",
    "for month in [str(i).zfill(2) for i in range(1, 13)]:\n",
    "    data = np.loadtxt(f'/data/img_nids/mlp/NIGEL_2014_{month}.csv', skiprows=1, delimiter=',', dtype=np.float32)\n",
    "    X_test, y_test = data[:, :-1], data[:, -1]\n",
    "    X_test  = torch.Tensor(X_test)\n",
    "    y_test  = torch.LongTensor(y_test)\n",
    "\n",
    "    cd = CustomDataset(subset=(X_test, y_test), transform=transform)\n",
    "    data_test  = DataLoader(cd, shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "\n",
    "    _, _, metrics = validate(device, epoch, optimizer, loss_fn, s, data_test)\n",
    "    all_metrics[month] = metrics\n",
    "    print(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66445fe7-aec7-40a7-b5d2-e2b9c758b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = []\n",
    "fnr = []\n",
    "\n",
    "for row in all_metrics.values():\n",
    "    fpr.append(row['fp'] / (row['fp'] + row['tn']))\n",
    "    fnr.append(row['fn'] / (row['fn'] + row['tp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60742976-639a-45ca-8803-c2cb90d294b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_cnn_resize.csv', 'w') as fp:\n",
    "    fp.write(\"fpr,fnr\\n\")\n",
    "    for _fp, _fn in zip(fpr, fnr):\n",
    "        fp.write(f\"{_fp},{_fn}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57ae419a-49a7-441a-aa68-e1feb2188169",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor()\n",
    "t = t.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd655262-b117-40ae-bf05-b6307dcb9fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97eaa14-a40a-4241-a8f4-959896740d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
